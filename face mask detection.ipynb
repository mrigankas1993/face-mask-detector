{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3183b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85cfa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "Epochs = 23\n",
    "Batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbc25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r\"E:\\maskdetection\\train\"\n",
    "types = ['Mask','Non Mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8947aa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images---\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9aa3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "047b8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in types:\n",
    "    path = os.path.join(dataset, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d001eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8d717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype='float32')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c2c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size = 0.18, stratify = labels, random_state = 40\n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     \n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c5ec1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.          0.9137255   0.7411765 ]\n",
      "   [ 1.          0.92156863  0.78039217]\n",
      "   [ 1.          0.90588236  0.79607844]\n",
      "   ...\n",
      "   [-0.23137254 -0.23921567 -0.25490195]\n",
      "   [-0.17647058 -0.19215685 -0.18431371]\n",
      "   [-0.20784312 -0.19999999 -0.23921567]]\n",
      "\n",
      "  [[ 1.          0.9137255   0.75686276]\n",
      "   [ 1.          0.9137255   0.7411765 ]\n",
      "   [ 1.          0.92156863  0.7254902 ]\n",
      "   ...\n",
      "   [-0.1607843  -0.16862744 -0.19999999]\n",
      "   [-0.17647058 -0.19999999 -0.23921567]\n",
      "   [-0.19215685 -0.19999999 -0.23921567]]\n",
      "\n",
      "  [[ 1.          0.9137255   0.75686276]\n",
      "   [ 1.          0.92156863  0.7647059 ]\n",
      "   [ 0.9843137   0.92156863  0.77254903]\n",
      "   ...\n",
      "   [-0.16862744 -0.17647058 -0.19215685]\n",
      "   [-0.19999999 -0.20784312 -0.23921567]\n",
      "   [-0.16862744 -0.17647058 -0.20784312]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.20784318  0.20784318  0.19215691]\n",
      "   [ 0.18431377  0.19215691  0.15294123]\n",
      "   [ 0.1686275   0.17647064  0.13725495]\n",
      "   ...\n",
      "   [-0.8039216  -0.84313726 -0.8117647 ]\n",
      "   [-0.84313726 -0.85882354 -0.8509804 ]\n",
      "   [-0.81960785 -0.8509804  -0.84313726]]\n",
      "\n",
      "  [[ 0.14509809  0.15294123  0.11372554]\n",
      "   [ 0.16078436  0.16078436  0.14509809]\n",
      "   [ 0.13725495  0.15294123  0.11372554]\n",
      "   ...\n",
      "   [ 0.2941177   0.254902    0.2313726 ]\n",
      "   [-0.5764706  -0.62352943 -0.62352943]\n",
      "   [-0.8745098  -0.90588236 -0.92941177]]\n",
      "\n",
      "  [[ 0.06666672  0.07450986  0.02745104]\n",
      "   [ 0.05098045  0.05882359  0.01176476]\n",
      "   [ 0.05098045  0.05882359  0.0196079 ]\n",
      "   ...\n",
      "   [ 0.54509807  0.5529412   0.5137255 ]\n",
      "   [ 0.49803925  0.47450984  0.43529415]\n",
      "   [-0.41176468 -0.41960782 -0.4588235 ]]]\n",
      "\n",
      "\n",
      " [[[-0.5137255  -0.5372549  -0.654902  ]\n",
      "   [-0.4980392  -0.5294118  -0.62352943]\n",
      "   [-0.4352941  -0.49019605 -0.5686275 ]\n",
      "   ...\n",
      "   [-0.77254903 -0.79607844 -0.8509804 ]\n",
      "   [-0.8039216  -0.827451   -0.88235295]\n",
      "   [-0.78039217 -0.81960785 -0.8666667 ]]\n",
      "\n",
      "  [[-0.42745095 -0.4588235  -0.5529412 ]\n",
      "   [-0.5294118  -0.56078434 -0.64705884]\n",
      "   [-0.4352941  -0.49019605 -0.5686275 ]\n",
      "   ...\n",
      "   [-0.77254903 -0.79607844 -0.8509804 ]\n",
      "   [-0.75686276 -0.78039217 -0.8352941 ]\n",
      "   [-0.7647059  -0.8039216  -0.8509804 ]]\n",
      "\n",
      "  [[-0.4823529  -0.5137255  -0.60784316]\n",
      "   [-0.5137255  -0.54509807 -0.6313726 ]\n",
      "   [-0.49019605 -0.54509807 -0.62352943]\n",
      "   ...\n",
      "   [-0.78039217 -0.8039216  -0.85882354]\n",
      "   [-0.7647059  -0.7882353  -0.84313726]\n",
      "   [-0.75686276 -0.79607844 -0.84313726]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.44313723 -0.49019605 -0.49019605]\n",
      "   [-0.4588235  -0.5058824  -0.5058824 ]\n",
      "   [-0.5137255  -0.56078434 -0.56078434]\n",
      "   ...\n",
      "   [-0.75686276 -0.77254903 -0.8666667 ]\n",
      "   [-0.44313723 -0.47450978 -0.5686275 ]\n",
      "   [-0.5372549  -0.5686275  -0.654902  ]]\n",
      "\n",
      "  [[-0.41960782 -0.46666664 -0.46666664]\n",
      "   [-0.44313723 -0.49019605 -0.49019605]\n",
      "   [-0.41176468 -0.4588235  -0.4588235 ]\n",
      "   ...\n",
      "   [-0.6784314  -0.7019608  -0.77254903]\n",
      "   [-0.47450978 -0.5058824  -0.6       ]\n",
      "   [-0.46666664 -0.4980392  -0.58431375]]\n",
      "\n",
      "  [[-0.46666664 -0.5137255  -0.5137255 ]\n",
      "   [-0.54509807 -0.5921569  -0.5921569 ]\n",
      "   [-0.4823529  -0.5137255  -0.52156866]\n",
      "   ...\n",
      "   [-0.6627451  -0.6862745  -0.7411765 ]\n",
      "   [-0.42745095 -0.4588235  -0.5529412 ]\n",
      "   [-0.4588235  -0.49019605 -0.5764706 ]]]\n",
      "\n",
      "\n",
      " [[[-0.5137255  -0.5921569  -0.6       ]\n",
      "   [-0.38823527 -0.4352941  -0.40392154]\n",
      "   [-0.27058822 -0.27058822 -0.20784312]\n",
      "   ...\n",
      "   [-0.56078434 -0.5921569  -0.6627451 ]\n",
      "   [-0.5372549  -0.56078434 -0.6313726 ]\n",
      "   [-0.56078434 -0.58431375 -0.654902  ]]\n",
      "\n",
      "  [[-0.44313723 -0.5137255  -0.49019605]\n",
      "   [-0.31764704 -0.35686272 -0.3098039 ]\n",
      "   [-0.2235294  -0.2235294  -0.1607843 ]\n",
      "   ...\n",
      "   [-0.60784316 -0.6313726  -0.7019608 ]\n",
      "   [-0.60784316 -0.6313726  -0.7019608 ]\n",
      "   [-0.62352943 -0.62352943 -0.6862745 ]]\n",
      "\n",
      "  [[-0.40392154 -0.44313723 -0.3960784 ]\n",
      "   [-0.27843136 -0.2862745  -0.23921567]\n",
      "   [-0.24705881 -0.2235294  -0.15294117]\n",
      "   ...\n",
      "   [-0.6313726  -0.654902   -0.70980394]\n",
      "   [-0.6627451  -0.6627451  -0.7254902 ]\n",
      "   [-0.654902   -0.6627451  -0.7019608 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.6392157  -0.64705884 -0.60784316]\n",
      "   [-0.6862745  -0.69411767 -0.654902  ]\n",
      "   [-0.6627451  -0.6627451  -0.64705884]\n",
      "   ...\n",
      "   [-0.03529412 -0.05098039 -0.04313725]\n",
      "   [-0.03529412 -0.05098039 -0.04313725]\n",
      "   [-0.05882353 -0.0745098  -0.06666666]]\n",
      "\n",
      "  [[-0.49019605 -0.5058824  -0.4980392 ]\n",
      "   [-0.35686272 -0.372549   -0.36470586]\n",
      "   [-0.26274508 -0.27058822 -0.2862745 ]\n",
      "   ...\n",
      "   [-0.05882353 -0.06666666 -0.08235294]\n",
      "   [-0.05882353 -0.06666666 -0.08235294]\n",
      "   [-0.06666666 -0.0745098  -0.09019607]]\n",
      "\n",
      "  [[-0.10588235 -0.15294117 -0.15294117]\n",
      "   [-0.05882353 -0.09803921 -0.12156862]\n",
      "   [-0.0745098  -0.11372548 -0.1372549 ]\n",
      "   ...\n",
      "   [-0.05882353 -0.06666666 -0.08235294]\n",
      "   [-0.06666666 -0.0745098  -0.09019607]\n",
      "   [-0.0745098  -0.08235294 -0.09803921]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 0.9843137   1.          0.99215686]\n",
      "   [ 0.9843137   1.          0.99215686]\n",
      "   [ 0.9843137   1.          0.99215686]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          0.24705887]\n",
      "   [ 1.          1.          0.24705887]\n",
      "   [ 1.          0.99215686  0.26274514]]\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  0.27058828]\n",
      "   [ 1.          0.99215686  0.27058828]\n",
      "   [ 1.          0.99215686  0.28627455]]\n",
      "\n",
      "  [[ 1.          1.          0.9843137 ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          0.34901965]\n",
      "   [ 1.          1.          0.34901965]\n",
      "   [ 1.          1.          0.34901965]]]\n",
      "\n",
      "\n",
      " [[[-0.8039216  -0.7019608  -0.75686276]\n",
      "   [-0.8039216  -0.7176471  -0.7647059 ]\n",
      "   [-0.8039216  -0.7176471  -0.78039217]\n",
      "   ...\n",
      "   [-0.5529412  -0.3490196  -0.23137254]\n",
      "   [-0.78039217 -0.5686275  -0.4352941 ]\n",
      "   [-0.7411765  -0.5372549  -0.41960782]]\n",
      "\n",
      "  [[-0.78039217 -0.6862745  -0.7647059 ]\n",
      "   [-0.78039217 -0.6862745  -0.7647059 ]\n",
      "   [-0.8117647  -0.7176471  -0.79607844]\n",
      "   ...\n",
      "   [-0.5686275  -0.36470586 -0.24705881]\n",
      "   [-0.7882353  -0.5921569  -0.4352941 ]\n",
      "   [-0.70980394 -0.5372549  -0.372549  ]]\n",
      "\n",
      "  [[-0.7411765  -0.6784314  -0.78039217]\n",
      "   [-0.77254903 -0.6862745  -0.79607844]\n",
      "   [-0.8039216  -0.7176471  -0.827451  ]\n",
      "   ...\n",
      "   [-0.5921569  -0.41176468 -0.2862745 ]\n",
      "   [-0.73333335 -0.56078434 -0.38039213]\n",
      "   [-0.5921569  -0.41960782 -0.23921567]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.6784314   0.5294118   0.21568632]\n",
      "   [ 0.6627451   0.5137255   0.20000005]\n",
      "   [ 0.6627451   0.5058824   0.21568632]\n",
      "   ...\n",
      "   [-0.38823527 -0.52156866 -0.4588235 ]\n",
      "   [-0.19215685 -0.34117645 -0.29411763]\n",
      "   [-0.17647058 -0.32549018 -0.29411763]]\n",
      "\n",
      "  [[ 0.6784314   0.5294118   0.21568632]\n",
      "   [ 0.6784314   0.5058824   0.20000005]\n",
      "   [ 0.6784314   0.5058824   0.21568632]\n",
      "   ...\n",
      "   [-0.08235294 -0.29411763 -0.38039213]\n",
      "   [-0.09019607 -0.3098039  -0.40392154]\n",
      "   [-0.06666666 -0.30196077 -0.38823527]]\n",
      "\n",
      "  [[ 0.7019608   0.5294118   0.22352946]\n",
      "   [ 0.6862745   0.5137255   0.20784318]\n",
      "   [ 0.6784314   0.5058824   0.21568632]\n",
      "   ...\n",
      "   [-0.04313725 -0.27058822 -0.41176468]\n",
      "   [-0.06666666 -0.3098039  -0.46666664]\n",
      "   [ 0.01176476 -0.24705881 -0.3960784 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.2862745  -0.38823527 -0.5137255 ]\n",
      "   [-0.30196077 -0.40392154 -0.5372549 ]\n",
      "   [-0.23137254 -0.3333333  -0.46666664]\n",
      "   ...\n",
      "   [ 0.07450986 -0.06666666 -0.17647058]\n",
      "   [ 0.04313731 -0.09803921 -0.20784312]\n",
      "   [ 0.10588241 -0.03529412 -0.14509803]]\n",
      "\n",
      "  [[-0.32549018 -0.41960782 -0.54509807]\n",
      "   [-0.29411763 -0.38039213 -0.52156866]\n",
      "   [-0.21568626 -0.30196077 -0.4588235 ]\n",
      "   ...\n",
      "   [ 0.082353   -0.05882353 -0.16862744]\n",
      "   [ 0.082353   -0.05882353 -0.16862744]\n",
      "   [ 0.12941182 -0.01176471 -0.12156862]]\n",
      "\n",
      "  [[-0.21568626 -0.32549018 -0.42745095]\n",
      "   [-0.14509803 -0.23137254 -0.372549  ]\n",
      "   [-0.18431371 -0.27058822 -0.41176468]\n",
      "   ...\n",
      "   [ 0.09803927 -0.03529412 -0.1607843 ]\n",
      "   [ 0.09019613 -0.05098039 -0.1607843 ]\n",
      "   [ 0.15294123  0.01176476 -0.09803921]]]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "023fc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the training image generator for data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63505f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "augument = ImageDataGenerator( rotation_range = 20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                         horizontal_flip=True, fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98744a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the MobileNetV2\n"
     ]
    }
   ],
   "source": [
    "print(\"loading the MobileNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7940c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "ground = MobileNetV2(weights='imagenet', include_top=False, input_tensor = Input(shape=(224, 224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a12f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainModel = ground.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8a76de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer average_pooling2d_6 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-858e0ae1e873>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMainModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mMainModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'flatten'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mMainModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mMainModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMainModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMainModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    876\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2597\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2599\u001b[1;33m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[0;32m   2600\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[0;32m   2601\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[0;32m    216\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer average_pooling2d_6 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 2)"
     ]
    }
   ],
   "source": [
    "MainModel = AveragePooling2D(pool_size = (5, 5))(MainModel)\n",
    "MainModel = Flatten(name= 'flatten')(MainModel)\n",
    "MainModel = Dense(128, activation = 'relu')(MainModel)\n",
    "MainModel = Dropout(0.5)(MainModel)\n",
    "MainModel = Dense(2, activation='softmax')(MainModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fd1a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=ground.input,outputs=MainModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "758eb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ground.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b43696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model\n"
     ]
    }
   ],
   "source": [
    "#compliling the model\n",
    "print(\"Compiling model\")\n",
    "opt = Adam(lr= learning_rate, decay= learning_rate / Epochs)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77bda22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "16/16 [==============================] - 79s 5s/step - loss: 0.8572 - accuracy: 0.5063 - val_loss: 0.6085 - val_accuracy: 0.7927\n",
      "Epoch 2/23\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.6128 - accuracy: 0.7511 - val_loss: 0.4394 - val_accuracy: 0.9472\n",
      "Epoch 3/23\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.4611 - accuracy: 0.8723 - val_loss: 0.3295 - val_accuracy: 0.9675\n",
      "Epoch 4/23\n",
      "16/16 [==============================] - 39s 2s/step - loss: 0.3856 - accuracy: 0.9069 - val_loss: 0.2532 - val_accuracy: 0.9736\n",
      "Epoch 5/23\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.2655 - accuracy: 0.9697 - val_loss: 0.1961 - val_accuracy: 0.9817\n",
      "Epoch 6/23\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.2424 - accuracy: 0.9654 - val_loss: 0.1570 - val_accuracy: 0.9878\n",
      "Epoch 7/23\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.2246 - accuracy: 0.9567 - val_loss: 0.1288 - val_accuracy: 0.9898\n",
      "Epoch 8/23\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.1782 - accuracy: 0.9740 - val_loss: 0.1067 - val_accuracy: 0.9898\n",
      "Epoch 9/23\n",
      "16/16 [==============================] - 42s 3s/step - loss: 0.1452 - accuracy: 0.9827 - val_loss: 0.0910 - val_accuracy: 0.9898\n",
      "Epoch 10/23\n",
      "16/16 [==============================] - 39s 2s/step - loss: 0.1439 - accuracy: 0.9740 - val_loss: 0.0788 - val_accuracy: 0.9898\n",
      "Epoch 11/23\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.1197 - accuracy: 0.9762 - val_loss: 0.0698 - val_accuracy: 0.9898\n",
      "Epoch 12/23\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.1120 - accuracy: 0.9784 - val_loss: 0.0618 - val_accuracy: 0.9898\n",
      "Epoch 13/23\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.0902 - accuracy: 0.9875 - val_loss: 0.0555 - val_accuracy: 0.9939\n",
      "Epoch 14/23\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.1068 - accuracy: 0.9827 - val_loss: 0.0506 - val_accuracy: 0.9919\n",
      "Epoch 15/23\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0757 - accuracy: 0.9870 - val_loss: 0.0472 - val_accuracy: 0.9919\n",
      "Epoch 16/23\n",
      "16/16 [==============================] - 57s 3s/step - loss: 0.0768 - accuracy: 0.9957 - val_loss: 0.0443 - val_accuracy: 0.9919\n",
      "Epoch 17/23\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.99 - 52s 3s/step - loss: 0.0719 - accuracy: 0.9913 - val_loss: 0.0410 - val_accuracy: 0.9939\n",
      "Epoch 18/23\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0751 - accuracy: 0.9848 - val_loss: 0.0368 - val_accuracy: 0.9959\n",
      "Epoch 19/23\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0653 - accuracy: 0.9913 - val_loss: 0.0346 - val_accuracy: 0.9959\n",
      "Epoch 20/23\n",
      "16/16 [==============================] - 50s 3s/step - loss: 0.0644 - accuracy: 0.9913 - val_loss: 0.0322 - val_accuracy: 0.9959\n",
      "Epoch 21/23\n",
      "16/16 [==============================] - 68s 4s/step - loss: 0.0565 - accuracy: 0.9870 - val_loss: 0.0297 - val_accuracy: 0.9959\n",
      "Epoch 22/23\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.0652 - accuracy: 0.9913 - val_loss: 0.0283 - val_accuracy: 0.9959\n",
      "Epoch 23/23\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0446 - accuracy: 0.9978 - val_loss: 0.0284 - val_accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "#train the head of the network\n",
    "H = model.fit(augument.flow(train_x, train_y, batch_size=BS), steps_per_epoch = len(train_x) // Batch_size, \n",
    "              validation_data = (train_x, train_y),\n",
    "              validation_steps = len(test_x) // Batch_size,\n",
    "              epochs = Epochs\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "474a44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating the trained CNN\n"
     ]
    }
   ],
   "source": [
    "print(\"evaluating the trained CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15747ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_x, batch_size = BS)\n",
    "# for every image in the training set we need to find the index of the label with the corresponding largest predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4800635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4af9208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mask       1.00      0.98      0.99        54\n",
      "    Non Mask       0.98      1.00      0.99        54\n",
      "\n",
      "    accuracy                           0.99       108\n",
      "   macro avg       0.99      0.99      0.99       108\n",
      "weighted avg       0.99      0.99      0.99       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the cassification report\n",
    "print(classification_report(test_y.argmax(axis = 1), prediction, target_names = lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "947c0e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model.....\n"
     ]
    }
   ],
   "source": [
    "#saving the model\n",
    "print('saving model.....')\n",
    "model.save('face_mask_detector.model', save_format = 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e5ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb579c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
